# 论文评估与分流系统（队列与栈应用）

## 项目简介
这是一个基于队列和栈数据结构的论文评估系统，用于筛选高被引论文并根据相似度指标进行分类处理。

## 功能特点
- 📋 **队列管理**：使用队列存储待评估的高被引论文ID
- 📚 **栈分流**：根据相似度将论文分流到不同栈中
- 🔍 **自动筛选**：仅处理被引次数超过阈值的论文
- 📊 **统计输出**：显示成功转化、待复审和忽略的论文数量

## 核心技术

### 队列（Queue）
队列是一种先进先出（FIFO）的线性数据结构，适合按顺序处理任务：
- **入队**：将被引次数 > 50 的论文ID加入队列尾部
- **出队**：从队列头部取出论文ID进行评估
- **应用场景**：任务调度、顺序处理

### 栈（Stack）
栈是一种后进先出（LIFO）的线性数据结构，适合临时存储和批量处理：
- **成功栈**：存储相似度 > 0.50 的高质量转化记录
- **复审栈**：存储相似度 0.40~0.50 的待复审记录
- **特点**：最后入栈的记录最先被处理

### 数据流程
```
DeepDiveAI_Cited.csv (被引数据)
         ↓
    入队筛选 (被引 > 50)
         ↓
      队列处理
         ↓
DeepCosineAI.csv (相似度数据)
         ↓
      分流判断
    ↙    ↓    ↘
成功栈  复审栈  忽略
(>0.50) (0.40~0.50) (≤0.40)
```

## 使用方法

### 1. 准备数据文件
需要两个 CSV 文件：
- **DeepDiveAI_Cited.csv**：包含论文ID和被引次数
  - 第1列：论文ID
  - 第2列：被引次数

- **DeepCosineAI.csv**：包含论文ID和相似度
  - 第1列：论文ID
  - 第3列：相似度得分

### 2. 修改文件路径
在代码第19-20行修改为你的文件路径：
```cpp
string deepdive_cited_path = "your_path/DeepDiveAI_Cited.csv";
string cosine_path = "your_path/DeepCosineAI.csv";
```

### 3. 调整阈值参数（可选）
在代码第23-26行可自定义阈值：
```cpp
const int CITED_THRESHOLD = 50;        // 被引次数阈值
const int QUEUE_LIMIT = 1000;          // 队列容量上限
const double HIGH_SIMILARITY = 0.50;   // 成功转化阈值
const double MEDIUM_SIMILARITY = 0.40; // 复审阈值
```

### 4. 编译运行
```bash
g++ experiment_2_1st.cpp -o paper_evaluation
./paper_evaluation
```

## 输出示例
```
开始读取 DeepDiveAI_Cited.csv 并入队...
入队完成，共入队 1000 个论文ID

开始处理队列并分流...
已处理 100 个论文ID...
已处理 200 个论文ID...
...

========== 处理完成 ==========
总处理数: 1000
成功转化 (相似度 > 0.50): 356
待复审 (0.40 < 相似度 <= 0.50): 482
已忽略 (相似度 <= 0.40 或未找到): 162
```

## 处理逻辑

### 第一步：入队审核
- 读取 `DeepDiveAI_Cited.csv`
- 筛选被引次数 > 50 的论文
- 将论文ID加入评估队列
- 限制队列最多1000条记录

### 第二步：出队处理
- 从队列中取出论文ID
- 在 `DeepCosineAI.csv` 中查找对应记录
- 提取相似度数据

### 第三步：分流存储
根据相似度分流：
- **> 0.50**：成功转化论文，压入成功栈
- **0.40~0.50**：需要人工复审，压入复审栈
- **≤ 0.40**：质量不达标，直接忽略

## 应用场景
- 学术论文质量评估
- 科研成果转化筛选
- 数据结构与算法学习（队列与栈的应用）
- 批量数据分类处理
- 工作流管理系统

## 算法复杂度
- 时间复杂度：O(n × m)，其中 n 为队列长度，m 为 CosineAI 数据集大小
- 空间复杂度：O(n)，主要用于队列和栈的存储
